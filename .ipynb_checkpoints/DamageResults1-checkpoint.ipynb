{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7863cb8dd51c4d71861c048ae053a6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultipleInteract(children=(SelectMultiple(description='File Name', options=('01-05-2020_02-37-05-347.csvâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "#--------------   GET THE LIST OF CSV FILES FROM MONGO WEB   ----------------------\n",
    "#---------------------------------------------------------------------------------\n",
    "import pymongo #import the pymongo pip\n",
    "import datetime\n",
    "#mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw?retryWrites=false')\n",
    "db = client.test_database\n",
    "db = client['heroku_6x00zflw']\n",
    "collection = db['entangelment']\n",
    "dataset = collection.find_one()#find remote data on mongodb server.\n",
    "#dataset\n",
    "#---------------------------------------------------------------------------\n",
    "#--------------   PRINT THE LIST BOX FOR PROCESSING   ----------------------\n",
    "#---------------------------------------------------------------------------\n",
    "import ipywidgets as widgets\n",
    "mainarray = {} #initialize the main array\n",
    "filenamelist = [] #initialize the csv array of filenames\n",
    "\n",
    "for i in dataset['date']: \n",
    "    dataloop = i['filename']\n",
    "    #print(dataloop)     \n",
    "    filenamelist.append(dataloop)\n",
    "\n",
    "\n",
    "class SelectMultipleInteract(widgets.HBox):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.W1 = widgets.SelectMultiple(\n",
    "            options=filenamelist,\n",
    "            rows=8,\n",
    "            description='File Name',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.W2 = widgets.SelectMultiple(\n",
    "            options=['Channel 1.1', 'Channel 1.2','Channel 1.3','Channel 1.4','Channel 2.1','Channel 2.2','Channel 2.3','Channel 2.4'],\n",
    "            rows=8,\n",
    "            description='Channel',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.selectors = [self.W1, self.W2]\n",
    "        super().__init__(children=self.selectors)\n",
    "        self._set_observes()\n",
    "\n",
    "    def _set_observes(self):\n",
    "        for widg in self.selectors:\n",
    "            widg.observe(self._observed_function, names='value')\n",
    "\n",
    "    def _observed_function(self, widg):\n",
    "        for widg in self.selectors:\n",
    "            #print(widg.description)\n",
    "            #print(widg.get_interact_value())\n",
    "            mainarray[widg.description] = widg.get_interact_value()\n",
    "            \n",
    "SelectMultipleInteract()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'File': {'file name': '01-05-2020_02-37-05-347.csv', 'Channel Data': [{'Channel Name': 'Channel 1.1'}, {'Channel Name': 'Channel 1.2'}, {'Channel Name': 'Channel 1.3'}, {'Channel Name': 'Channel 1.4'}, {'Channel Name': 'Channel 2.1'}, {'Channel Name': 'Channel 2.2'}, {'Channel Name': 'Channel 2.3'}, {'Channel Name': 'Channel 2.4'}]}}\n",
      "['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4', 'Channel 2.1', 'Channel 2.2', 'Channel 2.3', 'Channel 2.4']\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------\n",
    "#--------------   MAIN ARRAY CREATED   ----------------------\n",
    "#------------------------------------------------------------\n",
    "mainarray\n",
    "path = r'C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\CSV\\\\'\n",
    "Files =[]\n",
    "JSONStructure = []\n",
    "Channels = [] \n",
    "tempVar= []\n",
    "tempVar2= []\n",
    " \n",
    "\n",
    "for i in range(len(mainarray['File Name'])):\n",
    "    \n",
    "    Files.append(path+mainarray['File Name'][i])\n",
    "    #for j in range(len(mainarray['Channel'])):\n",
    "     #   ChannelsA.append(mainarray['Channel'][j])  \n",
    "        \n",
    "    tempVarArray= []\n",
    "    for Channel in mainarray['Channel']:\n",
    "        Channel = Channel.strip('\\\"')\n",
    "        Channels.append(Channel)        \n",
    "        tempVar =   { 'Channel Name':Channel,\n",
    "                    \n",
    "                    }\n",
    "        tempVarArray.append(tempVar)\n",
    "    tempVar2 = {\n",
    "        \"File\" : {\n",
    "                'file name':mainarray['File Name'][i],\n",
    "                \"Channel Data\" : tempVarArray\n",
    "                }\n",
    "    }               \n",
    "    JSONStructure.append(tempVar2)\n",
    "\n",
    "print(JSONStructure[0])\n",
    "Channels = list(dict.fromkeys(Channels)) # remove duplicates inside the channel list\n",
    "#print(mainarray['Channel'])\n",
    "print(Channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################################################################################\n",
    "######################################### Importing Modules ################################################\n",
    "############################################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import scipy.fftpack as sf\n",
    "import scipy.signal as sig\n",
    "import rainflow\n",
    "import pandas\n",
    "import glob # module for reading files from a directory\n",
    "import os # module for getting only the filename not the whole path\n",
    "from pylab import*\n",
    "import json\n",
    "########################################################################################################\n",
    "##################################### Create a Low Path Filter #########################################\n",
    "########################################################################################################\n",
    "\n",
    "Fs = 50;\n",
    "o = 10;\n",
    "fc = np.array([1]) #Cut Off Frequncy\n",
    "wc = 2*fc/Fs;\n",
    "[b,a] = sig.butter(o, wc, btype = 'lowpass')\n",
    "# filter response\n",
    "[W,h] = sig.freqz(b,a, worN=1024)\n",
    "W = Fs* W/(2*pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\CSV\\\\01-05-2020_02-37-05-347.csv\n",
      "Begin, FilteredSignal\n",
      "Begin Channel, GetChannelData\n",
      "End of function, GetChannelData\n",
      "End, FilteredSignal\n",
      "Begin, RainFlow\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-826aa5f5c25f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mFileResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChannel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# store Channel name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[0mab1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFilteredSignal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mChannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[0mab2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRainFlow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mab1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mChannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m         \u001b[0mFileResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mab2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#damage 50 %\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mFileResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mab2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#damage 97.7%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-236-826aa5f5c25f>\u001b[0m in \u001b[0;36mRainFlow\u001b[1;34m(Filtered, Channel)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# Detailed output, like cycle lows, highs or means, use extract_cycles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_end\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrainflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_cycles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m#mn.append(mean)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "#########################################################################################################\n",
    "############   generate a matrix of seq, x,y ; sequence, time and stresses    ##########################\n",
    "############               Apply correction factor per weld class             #########################\n",
    "#########################################################################################################\n",
    "# n = GetChannelData(Channel)[1]\n",
    "# y = GetChannelData(Channel)[0]\n",
    "\n",
    "def GetChannelData(Channel):\n",
    "    print('Begin Channel, GetChannelData')\n",
    "    ChannelData =[]\n",
    "    yZ=Channel\n",
    "    TimeLength=len(yZ)\n",
    "    seq=[round(x,1) for x in range(1, TimeLength+1)]\n",
    "    x1= [round(x*0.02,3) for x in range(0, TimeLength)]\n",
    "    data={'seq':seq,'x':x1,'y':yZ}\n",
    "    data = pandas.DataFrame(data, columns=['seq','x', 'y'])\n",
    "    data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "    x = data.x.tolist()\n",
    "    y = data.y.tolist()\n",
    "    Corr1 = 0.1840265*0.207 # Channel 1.1 to 1.4 weld class W\n",
    "    Corr2 = 0.4784689*0.207 # Channel 2.1 to 2.4 weld class F2\n",
    "    Slot1=['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4'] \n",
    "    if Channel.name in Slot1:\n",
    "        y = [float(p)*Corr1 for p in y if str(p) !='nan']\n",
    "        ChannelData.append(y)\n",
    "    else:\n",
    "        y = [float(p)*Corr2 for p in y if str(p) !='nan']\n",
    "        ChannelData.append(y)\n",
    "    l = np.size(y)\n",
    "    n = np.arange(0,l,1)\n",
    "    ChannelData.append(n)\n",
    "    print('End of function, GetChannelData')\n",
    "    return ChannelData\n",
    "############################################################################################################\n",
    "############################### Graphing / plotting function ###############################################\n",
    "############################################################################################################\n",
    "def myplot(x,y,Title, xlabel, ylabel):    \n",
    "    print('Begin, MyPlot')\n",
    "    fig =plt.figure()\n",
    "    plt.plot( x, y)\n",
    "    #x = plot(t,x)\n",
    "    fig.savefig('plot.png')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(Title)\n",
    "    plt.grid(True)\n",
    "    print('End, MyPlot')\n",
    "    return fig\n",
    "###############################################################################################################\n",
    "############################## Signal Characteristics and Fourier#############################################\n",
    "##############################################################################################################\n",
    "def FourierTransform(y):\n",
    "    print('Begin, FFT')\n",
    "    FourierResults = []\n",
    "    Fs = 50; #Sampling Frequency\n",
    "    l = np.size(y)\n",
    "    n = np.arange(0,l,1)\n",
    "    # Take spectral analysis\n",
    "    # calculating the fft\n",
    "    X_f = abs(sf.fft(yP))\n",
    "    l = np.size(y)\n",
    "    fr = (Fs/2)*np.linspace(0,1,l//2)\n",
    "    FourierResults.append(fr)\n",
    "    xl_m = (2/l)*abs(X_f[0:np.size(fr)]);\n",
    "    FourierResults.append(xl_m)\n",
    "    Db = 20*np.log10(xl_m)\n",
    "    FourierResults.append(Db)\n",
    "    print('End, FFT')\n",
    "    return FourierResults\n",
    "#####################################################################################################################\n",
    "############## Plotting Raw Data, Spectrum, and Filtired Signal per channel #########################################\n",
    "#####################################################################################################################\n",
    "\n",
    "def PlotSlot1():\n",
    "    print('Begin, PlotSlot1')\n",
    "    for Channel in Slot1:\n",
    "        #Plot Raw data Stress // by calling functions\n",
    "        myplot( GetChannelData(Channel)[1], GetChannelData(Channel)[0], Channel.name +' Raw Data', 'Time', 'Stress (MPa)')\n",
    "        #Plot the spectrum\n",
    "        myplot(FourierTransform(GetChannelData(Channel)[1])[0],FourierTransform(GetChannelData(Channel)[1])[2] , Channel.name +' Spectrum','Frequency','Amplitute')\n",
    "        #Filtered Signal\n",
    "        x_filt = sig.lfilter(b,a, GetChannelData(Channel)[0])\n",
    "        myplot(GetChannelData(Channel)[1],x_filt, Channel.name+' Filtered Signal', 'Time', 'Stress (MPa)')    \n",
    "    print('End, PlotSlot1')\n",
    "    plt.show()\n",
    "\n",
    "##########################################################################################################\n",
    "################################# Package The Filtered Signal  ###########################################\n",
    "##########################################################################################################\n",
    "def FilteredSignal(Channel):\n",
    "    print('Begin, FilteredSignal')\n",
    "    x_filt = sig.lfilter(b,a, GetChannelData(Channel)[0])\n",
    "    TimeLength=len(x_filt)\n",
    "    seq=[round(x,1) for x in range(1, TimeLength+1)]\n",
    "    x2= [round(x*0.02,3) for x in range(0, TimeLength)]\n",
    "    Filtered={'seq':seq,'xf':x2,'yf':x_filt}\n",
    "    Filtered= pandas.DataFrame(Filtered, columns=['seq','xf', 'yf'])\n",
    "    print('End, FilteredSignal')\n",
    "    return Filtered\n",
    "########################################################################################################################\n",
    "##########################################################################################################################\n",
    "############################################ RainFlow Counting ###########################################################\n",
    "##########################################################################################################################\n",
    "\n",
    "#Rainflow Counting\n",
    "#FilteredSignal(Channel)\n",
    "#RainFlow()[0] The CSV File\n",
    "#RainFlow()[1] The damages \n",
    "\n",
    "def RainFlow(Filtered, Channel):\n",
    "    print('Begin, RainFlow')\n",
    "    RainFlow_Results =[] #Initialize an empty list to store the results of Rainflow Algorithm\n",
    "    x = Filtered.xf.tolist()\n",
    "    y = round(Filtered['yf'],3).tolist()\n",
    "    # Rainflow Count Algorithm\n",
    "    # Function count_cycles returns a sorted list of the load ranges and the corresponding number of cycles\n",
    "    # 3 decimal digits is used for precision\n",
    "    val = rainflow.count_cycles(y, 3)\n",
    "    #print(\"Output (Range,Cycles) = \", val)\n",
    "    # Mean, Range , Cycle Count list use to store each point in 3-Dimension\n",
    "    mn = []\n",
    "    rg = []\n",
    "    z = []\n",
    "    # Detailed output, like cycle lows, highs or means, use extract_cycles\n",
    "    for rng, mean, count, i_start, i_end in rainflow.extract_cycles(y): \n",
    "        print(rng, mean, count, i_start, i_end) \n",
    "        #mn.append(mean)\n",
    "        \n",
    "   # for low, high, mult in rainflow.extract_cycles(y, True, True):\n",
    "       # mean = 0.5 * (high + low)\n",
    "        # Append Of The mean List\n",
    "       # mn.append(mean)\n",
    "        rng = high - low\n",
    "        # Append Of The Range List\n",
    "        rg.append(rng)\n",
    "    # Create a Data Frame using panda to better manage the list of range and cycle counts\n",
    "    # generated from rainflow.count_cycles function\n",
    "    d1 = {'range_cycles': val}\n",
    "    df2 = pandas.DataFrame(d1)\n",
    "    df2[['range', 'cycles']] = pandas.DataFrame(df2.range_cycles.values.tolist(), index=df2.index)\n",
    "    \n",
    "    \"\"\"\"\n",
    "    liss = df2[['range']].values.flatten()\n",
    "    liss2 = df2[['cycles']].values.flatten()\n",
    "    # Using the detail output of rainflow.extract_cycles function, extract the corresponding mean values in a list\n",
    "    new_range = []\n",
    "    new_mean = []\n",
    "    new_cycle = []\n",
    "    # For loop to extract the corresponding mean values\n",
    "    for xr in range(len(rg)):\n",
    "        for xv in range(len(val)):\n",
    "            if rg[xr] == liss[xv]:\n",
    "                new_range.append(liss[xv])\n",
    "                new_mean.append(mn[xr])\n",
    "                new_cycle.append(liss2[xv])\n",
    "\n",
    "    matrix_list = [new_range, new_mean, new_cycle]\n",
    "    #print(matrix_list)\n",
    "    df = pandas.DataFrame({'Mean_': new_mean, 'Range_': new_range, 'z': new_cycle})\n",
    "    # create pivot table with x(Range) rows, y(Mean)columns, z as values\n",
    "    lists = df.pivot_table(values='z', index='Mean_', columns='Range_')\n",
    "    # Write the Pivot table matrix in an excel(CSV) file: output_Test_Manual_sample.csv\n",
    "    finaldf = pandas.DataFrame(lists)\n",
    "    #RainFlow_Results.append(finaldf)\n",
    "    finaldf.to_csv('Output_Real_Sample.csv', index=True, header=True)\n",
    "    #######################################################################################\n",
    "    ############# To calculate the time between each peak and valley ######################\n",
    "    #######################################################################################\n",
    "    lenght = len(y)\n",
    "    peak_position = []\n",
    "    time_diff_peak = []\n",
    "    for cc in range(lenght):\n",
    "        if ((y[cc]>y[cc-1]) and ((cc+1)<lenght)):\n",
    "                if (y[cc +1]< y[cc]):\n",
    "                    peak_position.append(x[cc])\n",
    "                else:\n",
    "                    cc = cc + 1\n",
    "    for pt in range(len(peak_position)):\n",
    "        if(pt+1)< (len(peak_position)):\n",
    "            time_diff_peak.append(round (( peak_position[pt+1] - peak_position[pt]),2 ))\n",
    "    #print(\"Time Difference Between Peaks\", time_diff_peak)\n",
    "    valley_position = []\n",
    "    time_diff_valley = []\n",
    "    for vv in range(1, lenght, 1):\n",
    "        if y[vv] > y[vv - 1] and vv+1 < lenght:\n",
    "            if y[vv+1] > y[vv]:\n",
    "                vv = vv + 1\n",
    "            else:\n",
    "                valley_position.append(x[vv-1])\n",
    "    for vt in range(len(valley_position)):\n",
    "        if(vt+1) < (len(peak_position)):\n",
    "            time_diff_valley.append(round((valley_position[vt+1] - valley_position[vt]), 2))\n",
    "    #print(\"Time Difference Between Valleys\", time_diff_valley)\n",
    "    gg = []\n",
    "    for g in range(len(time_diff_peak)):\n",
    "        gg.append(g)\n",
    "    plt.plot(gg, time_diff_peak)\n",
    "    plt.xlabel('Count_peaks')\n",
    "    plt.ylabel('Time_different Amplitude')\n",
    "    plt.title('Time  between Peaks ')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    ll = []\n",
    "    for l in range(len(time_diff_valley)):\n",
    "     ll.append(l)\n",
    "    plt.plot(ll, time_diff_valley)\n",
    "    plt.xlabel('Count_valleys')\n",
    "    plt.ylabel('Time_different Amplitude')\n",
    "    plt.title('Time  between Valleys ')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    ########################### Compute the damage ############################\n",
    "    ###########################################################################\n",
    "    # 50% probability of failure\n",
    "    # LogCo=12.6007, d = 0, m = 3, delta = 0.2095 weld class D\n",
    "    damage1 = 0 #50 % damage\n",
    "    damage2 = 0 # 97.7 % damage\n",
    "    Slot1=['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4'] \n",
    "    if Channel in Slot1 :\n",
    "        for num1, num2 in zip(df2['range'], df2['cycles']):\n",
    "            Nfw=10**(11.5662-3*np.log10(num1))\n",
    "            Ni = (num2/Nfw)*100\n",
    "            damage1=damage1+Ni\n",
    "    else:\n",
    "         for num1, num2 in zip(df2['range'], df2['cycles']):\n",
    "            Nfw=10**(12.0900-3*np.log10(num1))\n",
    "            Ni = (num2/Nfw)*100\n",
    "            damage1=damage1+Ni\n",
    "    #print('The damage is',damage1,'%,',' Based on 50 % probability of survival') \n",
    "    #97.7% probability of survival\n",
    "    if Channel in Slot1 :\n",
    "        for num1, num2 in zip(df2['range'], df2['cycles']):\n",
    "            Nfw=10**(11.5662-0.1846*2-3*np.log10(num1))\n",
    "            #print(Nfw)\n",
    "            Ni = (num2/Nfw)*100\n",
    "            #print(Ni)\n",
    "            damage2=damage2+Ni\n",
    "    else:\n",
    "        for num1, num2 in zip(df2['range'], df2['cycles']):\n",
    "            Nfw=10**(12.090-0.2279*2-3*np.log10(num1))\n",
    "            #print(Nfw)\n",
    "            Ni = (num2/Nfw)*100\n",
    "            #print(Ni)\n",
    "            damage2=damage2+Ni\n",
    "   # print('The damage is',damage2,'%,',' Based on 97.7 % probability of survival') \n",
    "    #Append the damages \n",
    "    RainFlow_Results.append(damage1)\n",
    "    RainFlow_Results.append(damage2)\n",
    "    return RainFlow_Results\n",
    "\n",
    "#####################################################################################################\n",
    "################################  Running the Script Section ########################################\n",
    "############################### Reading CSV Files From Folder #######################################\n",
    "#####################################################################################################\n",
    "\n",
    "path = r'C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\CSV\\\\' # Specify the folder with CSV files\n",
    "Files =[] # empty array to store Files\n",
    "FileResults = [] #\n",
    "ChannelData = []\n",
    "for i in range(len(mainarray['File Name'])):\n",
    "    Files.append(mainarray['File Name'][i])\n",
    "    \n",
    "RawData = pandas.DataFrame() # Initialize an empty dataframe \n",
    "for file_nameShort in Files:\n",
    "    file_name = path+file_nameShort\n",
    "    FileResults.append(file_name) # store the filename\n",
    "    print(file_name)\n",
    "    x = pandas.read_csv(file_name, delimiter=';',low_memory=False)\n",
    "    x = x.drop(x.tail(5).index)\n",
    "    # Calling the function on each Filename\n",
    "    #print(Channels)\n",
    "    for Channel in Channels:\n",
    "        #print(Channel)\n",
    "        FileResults.append(Channel) # store Channel name\n",
    "        ab1 = FilteredSignal(x[Channel])\n",
    "        ab2 = RainFlow(ab1,Channel)\n",
    "        FileResults.append(ab2[0])  #damage 50 %\n",
    "        FileResults.append(ab2[1])  #damage 97.7%\n",
    "\n",
    "        #RainFlow(FilteredSignal(x[Channel]), x[Channel])[1]\n",
    "\n",
    "        FileResults.append(ab1.min()[2]) # min\n",
    "        FileResults.append(ab1.max()[2]) # max\n",
    "        \n",
    "        #print(Channel)\n",
    "        #print(file_name)\n",
    "        \n",
    "        #Assign outputs to JSONStructure\n",
    "        #1. Find the File name in the JSONStructure we are looking for.\n",
    "        for i in JSONStructure:\n",
    "            #print(i['File']['file name'] ,'gggggggggggggggggggggg', file_nameShort,'sdsdsdsdsdsdsd')\n",
    "            if i['File']['file name'] == file_nameShort:\n",
    "                #2. Find the Channel Name We are looking for in the JSONStructure.\n",
    "                for j in i['File']['Channel Data']:\n",
    "                    if j['Channel Name'] == Channel:\n",
    "                        #3. Assign the Data\n",
    "                        #print(j['Channel Name'] ,'gggggggggggggg',Channel,'fgffgfgfgfgfgfgfg')\n",
    "                        j['50 Damage'] = ab2[0]\n",
    "                        j['97 Damage'] = ab2[1]\n",
    "                        j['Minimum Stress']=ab1.min()[2]\n",
    "                        j['Maximum Stress']=ab1.max()[2]          \n",
    "        #RainFlow(FilteredSignal(x[Channel]), x[Channel]\n",
    "        \n",
    "        \n",
    "        \n",
    "    RawData = pandas.concat([RawData.reset_index(drop=True),x.reset_index(drop=True)], axis= 0, sort=False)\n",
    "RawData = pandas.DataFrame(RawData, columns=['Channel 1.1', 'Channel 1.2','Channel 1.3','Channel 1.4','Channel 2.1','Channel 2.2','Channel 2.3','Channel 2.4'])\n",
    "ChannelList=['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4']\n",
    "############################################# Pactkage the file to be posted ################################\n",
    "LC =len(Channels)\n",
    "FilePackage = [FileResults[i:i+5*LC+1] for i in range(0, len(FileResults), 5*LC+1)]\n",
    "##########################################################################################################\n",
    "################################# Running the Combined Files #############################################\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.634561347745435e-13\n",
      "1.6642902629484857\n"
     ]
    }
   ],
   "source": [
    "#print(JSONStructure[0]['File']['Channel Data'])\n",
    "print(JSONStructure[0]['File']['Channel Data'][1]['Minimum Stress'])\n",
    "print(JSONStructure[0]['File']['Channel Data'][1]['Maximum Stress'])\n",
    "#len(JSONStructure[0]['File']['Channel Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Channel 1.4', '50 Damage': 4.3378717819822436e-06, '97 Damage': 1.0150249346650269e-05, 'Maximum Stress Range': 21.58327533288915}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "##########     POST PROCESSING OF DATASET   ###########\n",
    "#######################################################\n",
    "\n",
    "dataset = []\n",
    "channelList = ['Channel 1.1', 'Channel 1.2','Channel 1.3','Channel 1.4','Channel 2.1','Channel 2.2','Channel 2.3','Channel 2.4']\n",
    "for j in range(len(Channels)):\n",
    "    dataset.append({\n",
    "        'name' : Channels[j],\n",
    "        '50 Damage' : 0 ,\n",
    "        '97 Damage':0,\n",
    "        'Stress Range':[],\n",
    "        'Maximum Stress Range':0,\n",
    "    })  \n",
    "for i in range(len(JSONStructure)):#Loop throguh the JSON object , and view each file name.\n",
    "    for j in range(len(JSONStructure[i]['File']['Channel Data'])): #Loop through the channel data to view each channel dataset.      \n",
    "        ChannelName = JSONStructure[i]['File']['Channel Data'][j]['Channel Name'] # define a variable to channelname.\n",
    "       \n",
    "        for j in range(len(Channels)):#Loop through the summary data array and find the place to put the data.\n",
    "            if ChannelName == dataset[j]['name']:#Check that the right channel has been found.\n",
    "                dataset[j]['50 Damage'] = dataset[j]['50 Damage'] + JSONStructure[i]['File']['Channel Data'][j]['50 Damage']#Add the data sets together into the storage array.\n",
    "                dataset[j]['97 Damage'] = dataset[j]['97 Damage'] + JSONStructure[i]['File']['Channel Data'][j]['97 Damage']#Add the data sets together into the storage array.\n",
    "                dataset[j]['Stress Range'].append(JSONStructure[i]['File']['Channel Data'][j]['Maximum Stress'] -JSONStructure[i]['File']['Channel Data'][j]['Minimum Stress']) # Calculate stress range \n",
    "#print(dataset)                \n",
    "for i in range(len(dataset)):\n",
    "    dataset[i]['Maximum Stress Range']  = max(dataset[i]['Stress Range']) \n",
    "    dataset[i].pop('Stress Range')\n",
    "print(dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo #import the pymongo pip\n",
    "import datetime\n",
    "#mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw?retryWrites=false')\n",
    "db = client.test_database\n",
    "db = client['heroku_6x00zflw']\n",
    "collection = db['fines']\n",
    " \n",
    "post = {\"author\": \"jon\",\n",
    "        'data':JSONStructure,\n",
    "        'summary':dataset,\n",
    "       }\n",
    "post_id = collection.insert_one(post)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-bf97e3233bfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msignal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_end\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrainflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_cycles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 3)"
     ]
    }
   ],
   "source": [
    "from math import sin, cos\n",
    "\n",
    "time = [4.0 * i / 200 for i in range(200 + 1)]\n",
    "signal = [0.2 + 0.5 * sin(t) + 0.2 * cos(10*t) + 0.2 * sin(4*t) for t in time]\n",
    "for rng, mean, count, i_start, i_end in rainflow.extract_cycles(signal): \n",
    "    print(rng, mean, count, i_start, i_end) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
