{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36d813f6ba64a41917a0bb89c7ac19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultipleInteract(children=(SelectMultiple(description='File Name', options=('01-07-2020_00-44-12-770.csvâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "#--------------   GET THE LIST OF CSV FILES FROM MONGO WEB   ----------------------\n",
    "#---------------------------------------------------------------------------------\n",
    "import pymongo #import the pymongo pip\n",
    "import datetime\n",
    "#mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw?retryWrites=false')\n",
    "db = client.test_database\n",
    "db = client['heroku_6x00zflw']\n",
    "collection = db['entangelment']\n",
    "#dataset = collection.find_one()#find remote data on mongodb server.\n",
    "dataset = collection.find_one( sort=[( '_id', pymongo.DESCENDING )])\n",
    "#dataset\n",
    "#---------------------------------------------------------------------------\n",
    "#--------------   PRINT THE LIST BOX FOR PROCESSING   ----------------------\n",
    "#---------------------------------------------------------------------------\n",
    "import ipywidgets as widgets\n",
    "mainarray = {} #initialize the main array\n",
    "filenamelist = [] #initialize the csv array of filenames\n",
    "\n",
    "for i in dataset['date']: \n",
    "    dataloop = i['filename']\n",
    "    #print(dataloop)     \n",
    "    filenamelist.append(dataloop)\n",
    "\n",
    "\n",
    "class SelectMultipleInteract(widgets.HBox):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.W1 = widgets.SelectMultiple(\n",
    "            options=filenamelist,\n",
    "            rows=8,\n",
    "            description='File Name',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.W2 = widgets.SelectMultiple(\n",
    "            options=['Channel 1.1', 'Channel 1.2','Channel 1.3','Channel 1.4','Channel 2.1','Channel 2.2','Channel 2.3','Channel 2.4'],\n",
    "            rows=8,\n",
    "            description='Channel',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.selectors = [self.W1, self.W2]\n",
    "        super().__init__(children=self.selectors)\n",
    "        self._set_observes()\n",
    "\n",
    "    def _set_observes(self):\n",
    "        for widg in self.selectors:\n",
    "            widg.observe(self._observed_function, names='value')\n",
    "\n",
    "    def _observed_function(self, widg):\n",
    "        for widg in self.selectors:\n",
    "            #print(widg.description)\n",
    "            #print(widg.get_interact_value())\n",
    "            mainarray[widg.description] = widg.get_interact_value()\n",
    "            \n",
    "SelectMultipleInteract()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'File': {'file name': '01-07-2020_00-44-12-770.csv', 'Duration': '6:00:00', 'Channel Data': [{'Channel Name': 'Channel 1.1'}, {'Channel Name': 'Channel 1.2'}, {'Channel Name': 'Channel 1.3'}, {'Channel Name': 'Channel 1.4'}, {'Channel Name': 'Channel 2.1'}, {'Channel Name': 'Channel 2.2'}, {'Channel Name': 'Channel 2.3'}, {'Channel Name': 'Channel 2.4'}]}}\n",
      "['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4', 'Channel 2.1', 'Channel 2.2', 'Channel 2.3', 'Channel 2.4']\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------\n",
    "#--------------   MAIN ARRAY CREATED   ----------------------\n",
    "#------------------------------------------------------------\n",
    "mainarray\n",
    "path = r'C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\Fines\\CSV\\\\'\n",
    "Files =[]\n",
    "JSONStructure = []\n",
    "Channels = [] \n",
    "tempVar= []\n",
    "tempVar2= []\n",
    "\n",
    "#######################################\n",
    "########  READ THE CSV FILES  ########\n",
    "#####################################\n",
    "\n",
    "############################################\n",
    "########### Importing Modules ##############\n",
    "############################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import glob # module for reading files from a directory\n",
    "import os # module for getting only the filename not the whole path\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "path = r'C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\Fines\\CSV\\\\' # Specify the folder with CSV files\n",
    "    \n",
    "for i in range(len(mainarray['File Name'])):\n",
    "    \n",
    "    Files.append(path+mainarray['File Name'][i])\n",
    "    with open(path+mainarray['File Name'][i]) as file:\n",
    "        x = pandas.read_csv(file, delimiter=';',low_memory=False)#read in each CSV file\n",
    "        #Extract the start and end times on each CSV file\n",
    "        startTime= str(x.iloc[[0]]['Time'].values[0]) # string extract of start and end times for CSV\n",
    "        EndTime= str(x.iloc[[-5]]['Time'].values[0]) # string extract of start and end times for CSV\n",
    "        dateObject = str(startTime[0:10]).replace(\"-\", \" \")\n",
    "        timeObject = str(startTime[11:19]).replace(\"-\", \" \")\n",
    "        total = dateObject+' '+timeObject\n",
    "        dateObject = datetime.strptime(total, '%d %m %Y %H %M %S')\n",
    "        startTimeStr = str(dateObject)\n",
    "        startTime = dateObject\n",
    "\n",
    "        dateObject = str(EndTime[0:10]).replace(\"-\", \" \")\n",
    "        timeObject = str(EndTime[11:19]).replace(\"-\", \" \")\n",
    "        total = dateObject+' '+timeObject\n",
    "        dateObject = datetime.strptime(total, '%d %m %Y %H %M %S')\n",
    "        EndTimeStr = str(dateObject)\n",
    "        EndTime = dateObject\n",
    "\n",
    "\n",
    "        duration = EndTime - startTime\n",
    "\n",
    "        tempVarArray= []\n",
    "        for Channel in mainarray['Channel']:\n",
    "            Channel = Channel.strip('\\\"')\n",
    "            Channels.append(Channel)        \n",
    "            tempVar =   { 'Channel Name':Channel,\n",
    "\n",
    "                        }\n",
    "            tempVarArray.append(tempVar)\n",
    "        tempVar2 = {\n",
    "            \"File\" : {\n",
    "                    'file name':mainarray['File Name'][i],\n",
    "                    \"Duration\": str(duration),\n",
    "                    \"Channel Data\" : tempVarArray,\n",
    "\n",
    "                    }\n",
    "        }               \n",
    "        JSONStructure.append(tempVar2)\n",
    "        #file.close()\n",
    "\n",
    "print(JSONStructure[0])\n",
    "Channels = list(dict.fromkeys(Channels)) # remove duplicates inside the channel list\n",
    "#print(mainarray['Channel'])\n",
    "print(Channels)\n",
    "########################################################################################################################\n",
    "############################### Check the memory usage of each line of Code ############################################\n",
    "########################################################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pandas.read_csv(file, delimiter=';',low_memory=False)#read in each CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################################################################################\n",
    "######################################### Importing Modules ################################################\n",
    "############################################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import scipy.fftpack as sf\n",
    "import scipy.signal as sig\n",
    "import rainflow\n",
    "import pandas\n",
    "import glob # module for reading files from a directory\n",
    "import os # module for getting only the filename not the whole path\n",
    "from pylab import*\n",
    "import json\n",
    "import csv\n",
    "########################################################################################################\n",
    "##################################### Create a Low Path Filter #########################################\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "# filter response\n",
    "#[W,h] = sig.freqz(b,a, worN=1024)\n",
    "#W = Fs* W/(2*pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\Fines\\CSV\\\\01-07-2020_00-44-12-770.csv\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f4b0463db1cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    169\u001b[0m                             \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'97 Damage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mab2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                             \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Minimum Stress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mab1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                             \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Maximum Stress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mab1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "#########################################################################################################\n",
    "############   generate a matrix of seq, x,y ; sequence, time and stresses    ##########################\n",
    "############               Apply correction factor per weld class             #########################\n",
    "#########################################################################################################\n",
    "# n = GetChannelData(Channel)[1]\n",
    "# y = GetChannelData(Channel)[0]\n",
    "\n",
    "def GetChannelData(Channel):\n",
    "    #print('Begin Channel, GetChannelData')\n",
    "    ChannelData =[]\n",
    "    yZ=Channel\n",
    "    \n",
    "    Corr1 = 0.1840265*0.207 # Channel 1.1 to 1.4 weld class W\n",
    "    Corr2 = 0.4784689*0.207 # Channel 2.1 to 2.4 weld class F2\n",
    "    Slot1=['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4'] \n",
    "    if Channel.name in Slot1:\n",
    "        y = [float(p)*Corr1 for p in yZ if str(p) !='nan']\n",
    "        ChannelData.append(y)\n",
    "    else:\n",
    "        y = [float(p)*Corr2 for p in yZ if str(p) !='nan']\n",
    "        ChannelData.append(y)\n",
    "    \n",
    "    #ChannelData.append(n)\n",
    "   # print('End of function, GetChannelData')\n",
    "    return ChannelData\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "################################# Package The Filtered Signal  ###########################################\n",
    "##########################################################################################################\n",
    "def FilteredSignal(Channel):\n",
    "    Fs = 50;\n",
    "    o = 8;\n",
    "    fc = np.array([14]) #Cut Off Frequncy\n",
    "    wc = 2*fc/Fs;\n",
    "    [b,a] = sig.butter(o, wc, btype = 'lowpass')\n",
    "    #print(Channel.name)\n",
    "    #print('Begin, FilteredSignal')\n",
    "    #print(GetChannelData(Channel)[0])\n",
    "    #x_filt = sig.filtfilt(b,a, GetChannelData(Channel)[0]) # forward and backward\n",
    "    x_filt =  GetChannelData(Channel)[0] # process raw data\n",
    "    #x_filt = sig.lfilter(b,a, GetChannelData(Channel)[0]) # Forward only\n",
    "    \n",
    "    TimeLength=len(x_filt)\n",
    "    seq=[round(x,1) for x in range(1, TimeLength+1)]\n",
    "    x2= [round(x*0.02,3) for x in range(0, TimeLength)]\n",
    "    Filtered={'seq':seq,'xf':x2,'yf':x_filt}\n",
    "    Filtered= pandas.DataFrame(Filtered, columns=['seq','xf', 'yf'])\n",
    "    #plt.plot( Filtered['xf'], Filtered['yf'], label=Channel.name) # plot the filtered results.   \n",
    "    #print('End, FilteredSignal')\n",
    "    return Filtered\n",
    "########################################################################################################################\n",
    "##########################################################################################################################\n",
    "############################################ RainFlow Counting ###########################################################\n",
    "##########################################################################################################################\n",
    "\n",
    "#Rainflow Counting\n",
    "#FilteredSignal(Channel)\n",
    "#RainFlow()[0] The CSV File\n",
    "#RainFlow()[1] The damages \n",
    "\n",
    "def RainFlow(Filtered, Channel):\n",
    "    #print(Channel)\n",
    "    #print('Begin, RainFlow')\n",
    "    RainFlow_Results =[] #Initialize an empty list to store the results of Rainflow Algorithm\n",
    "    x = Filtered.xf.tolist()\n",
    "    y = round(Filtered['yf'],3).tolist()\n",
    "    # Rainflow Count Algorithm\n",
    "    # Function count_cycles returns a sorted list of the load ranges and the corresponding number of cycles\n",
    "    # 3 decimal digits is used for precision\n",
    "    #val = rainflow.count_cycles(y, 3)\n",
    "    #print(Channel)\n",
    "    #print(val)\n",
    "    #print(\"Output (Range,Cycles) = \", val)\n",
    "    # Mean, Range , Cycle Count list use to store each point in 3-Dimension\n",
    "\n",
    "   \n",
    "    Slot1=['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4'] \n",
    "    damage1 = 0 #50 % damage\n",
    "    damage2 = 0 # 97.7 % damage\n",
    "    # Detailed output, like cycle lows, highs or means, use extract_cycles\n",
    "    for rng, mean, count, i_start, i_end in rainflow.extract_cycles(y): \n",
    "        #print('rng',rng)\n",
    "        #print(count)\n",
    "        # compute the 50 % damage \n",
    "        if rng != 0: # if the range is zero no computation\n",
    "            if Channel in Slot1 :\n",
    "                Nfw=10**(11.5662-3*np.log10(rng))\n",
    "                Ni = (count/Nfw)*100\n",
    "                damage1=damage1+Ni\n",
    "            else:\n",
    "                Nfw=10**(12.0900-3*np.log10(rng))\n",
    "                Ni = (count/Nfw)*100\n",
    "                damage1=damage1+Ni\n",
    "\n",
    "            # Compute the 97.7 % damage\n",
    "            if Channel in Slot1 :\n",
    "                Nfw=10**(11.5662-0.1846*2-3*np.log10(rng))\n",
    "                #print(Nfw)\n",
    "                Ni = (count/Nfw)*100\n",
    "                #print(Ni)\n",
    "                damage2=damage2+Ni\n",
    "            else:\n",
    "                Nfw=10**(12.090-0.2279*2-3*np.log10(rng))\n",
    "                #print(Nfw)\n",
    "                Ni = (count/Nfw)*100\n",
    "                #print(Ni)\n",
    "                damage2=damage2+Ni\n",
    "    #print('The damage is',damage1,'%,',' Based on 50 % probability of survival') \n",
    "    #print('The damage is',damage2,'%,',' Based on 97.7 % probability of survival')\n",
    "    RainFlow_Results.append(damage1) # 50 % damage\n",
    "    RainFlow_Results.append(damage2) # 97.7 % damage\n",
    "    #print('End, RainFlow')\n",
    "    return RainFlow_Results\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "################################  Running the Script Section ########################################\n",
    "############################### Reading CSV Files From Folder #######################################\n",
    "#####################################################################################################\n",
    "\n",
    "path = r'C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\Fines\\CSV\\\\' # Specify the folder with CSV files\n",
    "Files =[] # empty array to store Files\n",
    "FileResults = [] #\n",
    "ChannelData = []\n",
    "for i in range(len(mainarray['File Name'])):\n",
    "    Files.append(mainarray['File Name'][i])\n",
    "    \n",
    "#RawData = pandas.DataFrame() # Initialize an empty dataframe \n",
    "for file_nameShort in Files:\n",
    "    file_name = path+file_nameShort\n",
    "    FileResults.append(file_name) # store the filename\n",
    "    print(file_name)\n",
    "    with open(file_name) as file:\n",
    "        x = pandas.read_csv(file, delimiter=';',low_memory=False, error_bad_lines = False)\n",
    "        #print(x)\n",
    "        #x = x.drop(x.head(5).index)\n",
    "        x = x.drop(x.tail(3).index)\n",
    "        # Calling the function on each Filename\n",
    "        #print(Channels)\n",
    "        for Channel in Channels:\n",
    "            #print(Channel)\n",
    "\n",
    "            FileResults.append(Channel) # store Channel name\n",
    "            ab1 = FilteredSignal(x[Channel]) # call the filtering the data and output a dataframe\n",
    "            ab2 = RainFlow(ab1,Channel) # using the filtered data return a list of damages \n",
    "            FileResults.append(ab2[0])  #damage 50 %\n",
    "            FileResults.append(ab2[1])  #damage 97.7%\n",
    "\n",
    "            #RainFlow(FilteredSignal(x[Channel]), x[Channel])[1]\n",
    "\n",
    "            FileResults.append(ab1.min()[2]) # min\n",
    "            FileResults.append(ab1.max()[2]) # max\n",
    "\n",
    "            #print(Channel)\n",
    "            #print(file_name)\n",
    "\n",
    "            #Assign outputs to JSONStructure\n",
    "            #1. Find the File name in the JSONStructure we are looking for.\n",
    "            for i in JSONStructure:\n",
    "                #print(i['File']['file name'] ,'gggggggggggggggggggggg', file_nameShort,'sdsdsdsdsdsdsd')\n",
    "                if i['File']['file name'] == file_nameShort:\n",
    "                    #2. Find the Channel Name We are looking for in the JSONStructure.\n",
    "                    for j in i['File']['Channel Data']:\n",
    "                        if j['Channel Name'] == Channel:\n",
    "                            #3. Assign the Data\n",
    "                            #print(j['Channel Name'] ,'gggggggggggggg',Channel,'fgffgfgfgfgfgfgfg')\n",
    "                            j['50 Damage'] = ab2[0]\n",
    "                            j['97 Damage'] = ab2[1]\n",
    "                            j['Minimum Stress']=ab1.min()[2]\n",
    "                            j['Maximum Stress']=ab1.max()[2] \n",
    "            file.close()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Channel 1.1', '50 Damage': 202783595.5589349, '97 Damage': 474496287.9914592, 'Maximum Stress Range': 578455.1159487753}\n",
      "{'name': 'Channel 1.2', '50 Damage': 1.5481097011536357e-05, '97 Damage': 3.622444431838114e-05, 'Maximum Stress Range': 9.42902752507128}\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "##########     POST PROCESSING OF DATASET   ###########\n",
    "#######################################################\n",
    "\n",
    "dataset = []\n",
    "channelList = ['Channel 1.1', 'Channel 1.2','Channel 1.3','Channel 1.4','Channel 2.1','Channel 2.2','Channel 2.3','Channel 2.4']\n",
    "for j in range(len(Channels)):\n",
    "    dataset.append({\n",
    "        'name' : Channels[j],\n",
    "        '50 Damage' : 0 ,\n",
    "        '97 Damage':0,\n",
    "        'Stress Range':[],\n",
    "        'Maximum Stress Range':0,\n",
    "    })  \n",
    "for i in range(len(JSONStructure)):#Loop throguh the JSON object , and view each file name.\n",
    "    for j in range(len(JSONStructure[i]['File']['Channel Data'])): #Loop through the channel data to view each channel dataset.      \n",
    "        ChannelName = JSONStructure[i]['File']['Channel Data'][j]['Channel Name'] # define a variable to channelname.\n",
    "       \n",
    "        for j in range(len(Channels)):#Loop through the summary data array and find the place to put the data.\n",
    "            if ChannelName == dataset[j]['name']:#Check that the right channel has been found.\n",
    "                dataset[j]['50 Damage'] = dataset[j]['50 Damage'] + JSONStructure[i]['File']['Channel Data'][j]['50 Damage']#Add the data sets together into the storage array.\n",
    "                dataset[j]['97 Damage'] = dataset[j]['97 Damage'] + JSONStructure[i]['File']['Channel Data'][j]['97 Damage']#Add the data sets together into the storage array.\n",
    "                dataset[j]['Stress Range'].append(JSONStructure[i]['File']['Channel Data'][j]['Maximum Stress'] -JSONStructure[i]['File']['Channel Data'][j]['Minimum Stress']) # Calculate stress range \n",
    "#print(dataset)                \n",
    "for i in range(len(dataset)):\n",
    "    dataset[i]['Maximum Stress Range']  = max(dataset[i]['Stress Range']) \n",
    "    dataset[i].pop('Stress Range')\n",
    "print(dataset[0])\n",
    "print(dataset[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo #import the pymongo pip\n",
    "import datetime\n",
    "#mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw?retryWrites=false')\n",
    "db = client.test_database\n",
    "db = client['heroku_6x00zflw']\n",
    "collection = db['fines']\n",
    " \n",
    "post = {\"author\": \"jon\",\n",
    "        \"timestamp\": datetime.datetime.utcnow(),\n",
    "        \"Description\":'Processed data with a low pass filter at a cut-off frequency of 14, 8Th order. second processing of June 2020 data.',\n",
    "        'data':JSONStructure,\n",
    "        'summary':dataset,\n",
    "        \n",
    "       }\n",
    "post_id = collection.insert_one(post)\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
