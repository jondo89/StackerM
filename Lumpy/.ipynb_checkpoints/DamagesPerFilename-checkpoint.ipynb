{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09910fab7ef44c08a7d3ccdfe1f20bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultipleInteract(children=(SelectMultiple(description='File Name', options=('01-03-2020_03-02-28-059.csvâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "#--------------   GET THE LIST OF CSV FILES FROM MONGO WEB   ----------------------\n",
    "#---------------------------------------------------------------------------------\n",
    "import pymongo #import the pymongo pip\n",
    "import datetime\n",
    "#mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw?retryWrites=false')\n",
    "db = client.test_database\n",
    "db = client['heroku_6x00zflw']\n",
    "collection = db['entangelmentlumpy']\n",
    "dataset = collection.find_one()#find remote data on mongodb server.\n",
    "#dataset\n",
    "#---------------------------------------------------------------------------\n",
    "#--------------   PRINT THE LIST BOX FOR PROCESSING   ----------------------\n",
    "#---------------------------------------------------------------------------\n",
    "import ipywidgets as widgets\n",
    "mainarray = {} #initialize the main array\n",
    "filenamelist = [] #initialize the csv array of filenames\n",
    "\n",
    "for i in dataset['date']: \n",
    "    dataloop = i['filename']\n",
    "    #print(dataloop)     \n",
    "    filenamelist.append(dataloop)\n",
    "\n",
    "\n",
    "class SelectMultipleInteract(widgets.HBox):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.W1 = widgets.SelectMultiple(\n",
    "            options=filenamelist,\n",
    "            rows=8,\n",
    "            description='File Name',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.W2 = widgets.SelectMultiple(\n",
    "            options=['Channel 1.1', 'Channel 1.2','Channel 1.3','Channel 1.4','Channel 2.1','Channel 2.2','Channel 2.3','Channel 2.4'],\n",
    "            rows=8,\n",
    "            description='Channel',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        self.selectors = [self.W1, self.W2]\n",
    "        super().__init__(children=self.selectors)\n",
    "        self._set_observes()\n",
    "\n",
    "    def _set_observes(self):\n",
    "        for widg in self.selectors:\n",
    "            widg.observe(self._observed_function, names='value')\n",
    "\n",
    "    def _observed_function(self, widg):\n",
    "        for widg in self.selectors:\n",
    "            #print(widg.description)\n",
    "            #print(widg.get_interact_value())\n",
    "            mainarray[widg.description] = widg.get_interact_value()\n",
    "            \n",
    "SelectMultipleInteract()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'File': {'file name': '01-05-2020_02-37-05-347.csv', 'Channel Data': [{'Channel Name': 'Channel 1.1'}, {'Channel Name': 'Channel 1.2'}, {'Channel Name': 'Channel 1.3'}, {'Channel Name': 'Channel 1.4'}, {'Channel Name': 'Channel 2.1'}, {'Channel Name': 'Channel 2.2'}, {'Channel Name': 'Channel 2.3'}, {'Channel Name': 'Channel 2.4'}]}}\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------\n",
    "#--------------   MAIN ARRAY CREATED   ----------------------\n",
    "#------------------------------------------------------------\n",
    "mainarray\n",
    "path = r'C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\CSV\\\\'\n",
    "Files =[]\n",
    "ChannelsA = []\n",
    "JSONStructure = []\n",
    "Channels = [] \n",
    "tempVar= []\n",
    "tempVar2= []\n",
    " \n",
    "\n",
    "for i in range(len(mainarray['File Name'])):\n",
    "    \n",
    "    Files.append(path+mainarray['File Name'][i])\n",
    "    #for j in range(len(mainarray['Channel'])):\n",
    "     #   ChannelsA.append(mainarray['Channel'][j])  \n",
    "        \n",
    "    tempVarArray= []\n",
    "    for Channel in mainarray['Channel']:\n",
    "        Channel = Channel.strip('\\\"')\n",
    "        Channels.append(Channel)        \n",
    "        tempVar =   { 'Channel Name':Channel,\n",
    "                    \n",
    "                    }\n",
    "        tempVarArray.append(tempVar)\n",
    "    tempVar2 = {\n",
    "        \"File\" : {\n",
    "                'file name':mainarray['File Name'][i],\n",
    "                \"Channel Data\" : tempVarArray\n",
    "                }\n",
    "    }               \n",
    "    JSONStructure.append(tempVar2)\n",
    "\n",
    "print(JSONStructure[0])\n",
    "\n",
    "#print(mainarray['Channel'])\n",
    "#print(Channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################################################################################\n",
    "######################################### Importing Modules ################################################\n",
    "############################################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import scipy.fftpack as sf\n",
    "import scipy.signal as sig\n",
    "import rainflow\n",
    "import pandas\n",
    "import glob # module for reading files from a directory\n",
    "import os # module for getting only the filename not the whole path\n",
    "from pylab import*\n",
    "import json\n",
    "########################################################################################################\n",
    "##################################### Create a Low Path Filter #########################################\n",
    "########################################################################################################\n",
    "\n",
    "Fs = 50;\n",
    "o = 10;\n",
    "fc = np.array([1]) #Cut Off Frequncy\n",
    "wc = 2*fc/Fs;\n",
    "[b,a] = sig.butter(o, wc, btype = 'lowpass')\n",
    "# filter response\n",
    "[W,h] = sig.freqz(b,a, worN=1024)\n",
    "W = Fs* W/(2*pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_cycles() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-04209c6b56db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mChannel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mChannels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mFileResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChannel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# store Channel name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mFileResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRainFlow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFilteredSignal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mChannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mChannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#damage 50 %\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[0mFileResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRainFlow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFilteredSignal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mChannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mChannel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#damage 97.7%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-04209c6b56db>\u001b[0m in \u001b[0;36mRainFlow\u001b[1;34m(Filtered, Channel)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;31m# Detailed output, like cycle lows, highs or means, use extract_cycles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrainflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_cycles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhigh\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;31m# Append Of The mean List\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: extract_cycles() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "#########################################################################################################\n",
    "############   generate a matrix of seq, x,y ; sequence, time and stresses    ##########################\n",
    "############               Apply correction factor per weld class             #########################\n",
    "#########################################################################################################\n",
    "# n = GetChannelData(Channel)[1]\n",
    "# y = GetChannelData(Channel)[0]\n",
    "\n",
    "def GetChannelData(Channel):\n",
    "    ChannelData =[]\n",
    "    yZ=Channel\n",
    "    TimeLength=len(yZ)\n",
    "    seq=[round(x,1) for x in range(1, TimeLength+1)]\n",
    "    x1= [round(x*0.02,3) for x in range(0, TimeLength)]\n",
    "    data={'seq':seq,'x':x1,'y':yZ}\n",
    "    data = pandas.DataFrame(data, columns=['seq','x', 'y'])\n",
    "    data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "    x = data.x.tolist()\n",
    "    y = data.y.tolist()\n",
    "    Corr1 = 0.1840265*0.207 # Channel 1.1 to 1.4 weld class W\n",
    "    Corr2 = 0.4784689*0.207 # Channel 2.1 to 2.4 weld class F2\n",
    "    Slot1=['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4'] \n",
    "    if Channel.name in Slot1:\n",
    "        y = [float(p)*Corr1 for p in y if str(p) !='nan']\n",
    "        ChannelData.append(y)\n",
    "    else:\n",
    "        y = [float(p)*Corr2 for p in y if str(p) !='nan']\n",
    "        ChannelData.append(y)\n",
    "    l = np.size(y)\n",
    "    n = np.arange(0,l,1)\n",
    "    ChannelData.append(n)\n",
    "    return ChannelData\n",
    "##########################################################################################################\n",
    "############################## Graphing / plotting function ##############################################\n",
    "##########################################################################################################\n",
    "def myplot(x,y,Title, xlabel, ylabel):    \n",
    "    fig =plt.figure()\n",
    "    plt.plot( x, y)\n",
    "    #x = plot(t,x)\n",
    "    fig.savefig('plot.png')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(Title)\n",
    "    plt.grid(True)\n",
    "    return fig\n",
    "#########################################################################################################\n",
    "######################## Signal Characteristics and Fourier##############################################\n",
    "#########################################################################################################\n",
    "def FourierTransform(y):\n",
    "    FourierResults = []\n",
    "    Fs = 50; #Sampling Frequency\n",
    "    l = np.size(y)\n",
    "    n = np.arange(0,l,1)\n",
    "    # Take spectral analysis\n",
    "    # calculating the fft\n",
    "    X_f = abs(sf.fft(yP))\n",
    "    l = np.size(y)\n",
    "    fr = (Fs/2)*np.linspace(0,1,l//2)\n",
    "    FourierResults.append(fr)\n",
    "    xl_m = (2/l)*abs(X_f[0:np.size(fr)]);\n",
    "    FourierResults.append(xl_m)\n",
    "    Db = 20*np.log10(xl_m)\n",
    "    FourierResults.append(Db)\n",
    "    return FourierResults\n",
    "#####################################################################################################################\n",
    "############## Plotting Raw Data, Spectrum, and Filtired Signal per channel #########################################\n",
    "#####################################################################################################################\n",
    "\n",
    "def PlotSlot1():\n",
    "    for Channel in Slot1:\n",
    "        #Plot Raw data Stress // by calling functions\n",
    "        myplot( GetChannelData(Channel)[1], GetChannelData(Channel)[0], Channel.name +' Raw Data', 'Time', 'Stress (MPa)')\n",
    "        #Plot the spectrum\n",
    "        myplot(FourierTransform(GetChannelData(Channel)[1])[0],FourierTransform(GetChannelData(Channel)[1])[2] , Channel.name +' Spectrum','Frequency','Amplitute')\n",
    "        #Filtered Signal\n",
    "        x_filt = sig.lfilter(b,a, GetChannelData(Channel)[0])\n",
    "        myplot(GetChannelData(Channel)[1],x_filt, Channel.name+' Filtered Signal', 'Time', 'Stress (MPa)')    \n",
    "    plt.show()\n",
    "\n",
    "##########################################################################################################\n",
    "################################# Package The Filtered Signal  ###########################################\n",
    "##########################################################################################################\n",
    "def FilteredSignal(Channel):\n",
    "    x_filt = sig.lfilter(b,a, GetChannelData(Channel)[0])\n",
    "    TimeLength=len(x_filt)\n",
    "    seq=[round(x,1) for x in range(1, TimeLength+1)]\n",
    "    x2= [round(x*0.02,3) for x in range(0, TimeLength)]\n",
    "    Filtered={'seq':seq,'xf':x2,'yf':x_filt}\n",
    "    Filtered= pandas.DataFrame(Filtered, columns=['seq','xf', 'yf'])\n",
    "    return Filtered\n",
    "########################################################################################################################\n",
    "##########################################################################################################################\n",
    "############################################ RainFlow Counting ###########################################################\n",
    "##########################################################################################################################\n",
    "\n",
    "#Rainflow Counting\n",
    "#FilteredSignal(Channel)\n",
    "#RainFlow()[0] The CSV File\n",
    "#RainFlow()[1] The damages \n",
    "\n",
    "def RainFlow(Filtered, Channel):\n",
    "    RainFlow_Results =[] #Initialize an empty list to store the results of Rainflow Algorithm\n",
    "    x = Filtered.xf.tolist()\n",
    "    y = round(Filtered['yf'],3).tolist()\n",
    "    # Rainflow Count Algorithm\n",
    "    # Function count_cycles returns a sorted list of the load ranges and the corresponding number of cycles\n",
    "    # 3 decimal digits is used for precision\n",
    "    val = rainflow.count_cycles(y, 3)\n",
    "    #print(\"Output (Range,Cycles) = \", val)\n",
    "    # Mean, Range , Cycle Count list use to store each point in 3-Dimension\n",
    "    mn = []\n",
    "    rg = []\n",
    "    z = []\n",
    "    # Detailed output, like cycle lows, highs or means, use extract_cycles\n",
    "    for low, high, mult in rainflow.extract_cycles(y, True, True):\n",
    "        mean = 0.5 * (high + low)\n",
    "        # Append Of The mean List\n",
    "        mn.append(mean)\n",
    "        rng = high - low\n",
    "        # Append Of The Range List\n",
    "        rg.append(rng)\n",
    "    # Create a Data Frame using panda to better manage the list of range and cycle counts\n",
    "    # generated from rainflow.count_cycles function\n",
    "    d1 = {'range_cycles': val}\n",
    "    df2 = pandas.DataFrame(d1)\n",
    "    df2[['range', 'cycles']] = pandas.DataFrame(df2.range_cycles.values.tolist(), index=df2.index)\n",
    "    \n",
    "    \"\"\"\"\n",
    "    liss = df2[['range']].values.flatten()\n",
    "    liss2 = df2[['cycles']].values.flatten()\n",
    "    # Using the detail output of rainflow.extract_cycles function, extract the corresponding mean values in a list\n",
    "    new_range = []\n",
    "    new_mean = []\n",
    "    new_cycle = []\n",
    "    # For loop to extract the corresponding mean values\n",
    "    for xr in range(len(rg)):\n",
    "        for xv in range(len(val)):\n",
    "            if rg[xr] == liss[xv]:\n",
    "                new_range.append(liss[xv])\n",
    "                new_mean.append(mn[xr])\n",
    "                new_cycle.append(liss2[xv])\n",
    "\n",
    "    matrix_list = [new_range, new_mean, new_cycle]\n",
    "    #print(matrix_list)\n",
    "    df = pandas.DataFrame({'Mean_': new_mean, 'Range_': new_range, 'z': new_cycle})\n",
    "    # create pivot table with x(Range) rows, y(Mean)columns, z as values\n",
    "    lists = df.pivot_table(values='z', index='Mean_', columns='Range_')\n",
    "    # Write the Pivot table matrix in an excel(CSV) file: output_Test_Manual_sample.csv\n",
    "    finaldf = pandas.DataFrame(lists)\n",
    "    #RainFlow_Results.append(finaldf)\n",
    "    finaldf.to_csv('Output_Real_Sample.csv', index=True, header=True)\n",
    "    #######################################################################################\n",
    "    ############# To calculate the time between each peak and valley ######################\n",
    "    #######################################################################################\n",
    "    lenght = len(y)\n",
    "    peak_position = []\n",
    "    time_diff_peak = []\n",
    "    for cc in range(lenght):\n",
    "        if ((y[cc]>y[cc-1]) and ((cc+1)<lenght)):\n",
    "                if (y[cc +1]< y[cc]):\n",
    "                    peak_position.append(x[cc])\n",
    "                else:\n",
    "                    cc = cc + 1\n",
    "    for pt in range(len(peak_position)):\n",
    "        if(pt+1)< (len(peak_position)):\n",
    "            time_diff_peak.append(round (( peak_position[pt+1] - peak_position[pt]),2 ))\n",
    "    #print(\"Time Difference Between Peaks\", time_diff_peak)\n",
    "    valley_position = []\n",
    "    time_diff_valley = []\n",
    "    for vv in range(1, lenght, 1):\n",
    "        if y[vv] > y[vv - 1] and vv+1 < lenght:\n",
    "            if y[vv+1] > y[vv]:\n",
    "                vv = vv + 1\n",
    "            else:\n",
    "                valley_position.append(x[vv-1])\n",
    "    for vt in range(len(valley_position)):\n",
    "        if(vt+1) < (len(peak_position)):\n",
    "            time_diff_valley.append(round((valley_position[vt+1] - valley_position[vt]), 2))\n",
    "    #print(\"Time Difference Between Valleys\", time_diff_valley)\n",
    "    gg = []\n",
    "    for g in range(len(time_diff_peak)):\n",
    "        gg.append(g)\n",
    "    plt.plot(gg, time_diff_peak)\n",
    "    plt.xlabel('Count_peaks')\n",
    "    plt.ylabel('Time_different Amplitude')\n",
    "    plt.title('Time  between Peaks ')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    ll = []\n",
    "    for l in range(len(time_diff_valley)):\n",
    "     ll.append(l)\n",
    "    plt.plot(ll, time_diff_valley)\n",
    "    plt.xlabel('Count_valleys')\n",
    "    plt.ylabel('Time_different Amplitude')\n",
    "    plt.title('Time  between Valleys ')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    ########################### Compute the damage ############################\n",
    "    ###########################################################################\n",
    "    # 50% probability of failure\n",
    "    # LogCo=12.6007, d = 0, m = 3, delta = 0.2095 weld class D\n",
    "    damage1 = 0 #50 % damage\n",
    "    damage2 = 0 # 97.7 % damage\n",
    "    Slot1=['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4'] \n",
    "    if Channel.name in Slot1 :\n",
    "        for num1, num2 in zip(df2['range'], df2['cycles']):\n",
    "            Nfw=10**(11.5662-3*np.log10(num1))\n",
    "            Ni = (num2/Nfw)*100\n",
    "            damage1=damage1+Ni\n",
    "    else:\n",
    "         for num1, num2 in zip(df2['range'], df2['cycles']):\n",
    "            Nfw=10**(12.0900-3*np.log10(num1))\n",
    "            Ni = (num2/Nfw)*100\n",
    "            damage1=damage1+Ni\n",
    "    #print('The damage is',damage1,'%,',' Based on 50 % probability of survival') \n",
    "    #97.7% probability of survival\n",
    "    if Channel.name in Slot1 :\n",
    "        for num1, num2 in zip(df2['range'], df2['cycles']):\n",
    "            Nfw=10**(11.5662-0.1846*2-3*np.log10(num1))\n",
    "            #print(Nfw)\n",
    "            Ni = (num2/Nfw)*100\n",
    "            #print(Ni)\n",
    "            damage2=damage2+Ni\n",
    "    else:\n",
    "        for num1, num2 in zip(df2['range'], df2['cycles']):\n",
    "            Nfw=10**(12.090-0.2279*2-3*np.log10(num1))\n",
    "            #print(Nfw)\n",
    "            Ni = (num2/Nfw)*100\n",
    "            #print(Ni)\n",
    "            damage2=damage2+Ni\n",
    "   # print('The damage is',damage2,'%,',' Based on 97.7 % probability of survival') \n",
    "    #Append the damages \n",
    "    RainFlow_Results.append(damage1)\n",
    "    RainFlow_Results.append(damage2)\n",
    "    return RainFlow_Results\n",
    "\n",
    "#####################################################################################################\n",
    "################################  Running the Script Section ########################################\n",
    "############################### Reading CSV Files From Folder #######################################\n",
    "#####################################################################################################\n",
    "\n",
    "path = r'C:\\Users\\Karabo Mogotlane\\Desktop\\StackerM\\CSV\\\\' # Specify the folder with CSV files\n",
    "Files =[] # empty array to store Files\n",
    "FileResults = [] #\n",
    "ChannelData = []\n",
    "for i in range(len(mainarray['File Name'])):\n",
    "    Files.append(mainarray['File Name'][i])\n",
    "    \n",
    "RawData = pandas.DataFrame() # Initialize an empty dataframe \n",
    "for file_nameShort in Files:\n",
    "    file_name = path+file_nameShort\n",
    "    FileResults.append(file_name) # store the filename\n",
    "    x = pandas.read_csv(file_name, delimiter=';',low_memory=False)\n",
    "    x = x.drop(x.tail(5).index)\n",
    "    # Calling the function on each Filename\n",
    "    for Channel in Channels:\n",
    "        FileResults.append(Channel) # store Channel name\n",
    "        FileResults.append(RainFlow(FilteredSignal(x[Channel]), x[Channel])[0])  #damage 50 %\n",
    "        FileResults.append(RainFlow(FilteredSignal(x[Channel]), x[Channel])[1])  #damage 97.7%\n",
    "\n",
    "        \n",
    "\n",
    "        FileResults.append(FilteredSignal(x[Channel]).min()[2]) # min\n",
    "        FileResults.append(FilteredSignal(x[Channel]).max()[2]) # max\n",
    "        \n",
    "        #print(Channel)\n",
    "        #print(file_name)\n",
    "        \n",
    "        #Assign outputs to JSONStructure\n",
    "        #1. Find the File name in the JSONStructure we are looking for.\n",
    "        for i in JSONStructure:\n",
    "            #print(i['File']['file name'] ,'gggggggggggggggggggggg', file_nameShort,'sdsdsdsdsdsdsd')\n",
    "            if i['File']['file name'] == file_nameShort:\n",
    "                #2. Find the Channel Name We are looking for in the JSONStructure.\n",
    "                for j in i['File']['Channel Data']:\n",
    "                    if j['Channel Name'] == Channel:\n",
    "                        #3. Assign the Data\n",
    "                        #print(j['Channel Name'] ,'gggggggggggggg',Channel,'fgffgfgfgfgfgfgfg')\n",
    "                        j['50 Damage'] = RainFlow(FilteredSignal(x[Channel]), x[Channel])[0]\n",
    "                        j['97 Damage'] = RainFlow(FilteredSignal(x[Channel]), x[Channel])[1]\n",
    "                        j['Minimum Stress']=FilteredSignal(x[Channel]).min()[2]\n",
    "                        j['Maximum Stress']=FilteredSignal(x[Channel]).max()[2]          \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    RawData = pandas.concat([RawData.reset_index(drop=True),x.reset_index(drop=True)], axis= 0, sort=False)\n",
    "RawData = pandas.DataFrame(RawData, columns=['Channel 1.1', 'Channel 1.2','Channel 1.3','Channel 1.4','Channel 2.1','Channel 2.2','Channel 2.3','Channel 2.4'])\n",
    "ChannelList=['Channel 1.1', 'Channel 1.2', 'Channel 1.3', 'Channel 1.4']\n",
    "############################################# Pactkage the file to be posted ################################\n",
    "LC =len(Channels)\n",
    "FilePackage = [FileResults[i:i+5*LC+1] for i in range(0, len(FileResults), 5*LC+1)]\n",
    "##########################################################################################################\n",
    "################################# Running the Combined Files #############################################\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Channel 1.1', 'Channel 1.2', 'Channel 1.1', 'Channel 1.2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Karabo Mogotlane\\\\Desktop\\\\StackerM\\\\CSV\\\\\\\\01-05-2020_08-37-05-385.csv',\n",
       " 'Channel 1.1',\n",
       " 3.670683683418424e-12,\n",
       " 8.589086199858123e-12,\n",
       " -0.521525459573791,\n",
       " -2.935417577386693e-13,\n",
       " 'Channel 1.2',\n",
       " 5.432054081127914e-12,\n",
       " 1.2710542440869964e-11,\n",
       " 3.903560159343332e-13,\n",
       " 0.7371740370859647,\n",
       " 'Channel 1.1',\n",
       " 3.670683683418424e-12,\n",
       " 8.589086199858123e-12,\n",
       " -0.521525459573791,\n",
       " -2.935417577386693e-13,\n",
       " 'Channel 1.2',\n",
       " 5.432054081127914e-12,\n",
       " 1.2710542440869964e-11,\n",
       " 3.903560159343332e-13,\n",
       " 0.7371740370859647]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(FileResults)\n",
    "LC =len(Channels)\n",
    "print(Channels)\n",
    "FilePackage = [FileResults[i:i+5*LC+1] for i in range(0, len(FileResults), 5*LC+1)]\n",
    "FilePackage[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0108158456509917e-11\n",
      "19.739799751069157\n"
     ]
    }
   ],
   "source": [
    "#print(JSONStructure[0]['File']['Channel Data'])\n",
    "print(JSONStructure[0]['File']['Channel Data'][3]['Minimum Stress'])\n",
    "print(JSONStructure[6]['File']['Channel Data'][3]['Maximum Stress'])\n",
    "#len(JSONStructure[0]['File']['Channel Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'50 Damage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-82706cb020d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannelList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#Loop through the summary data array and find the place to put the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mChannelName\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#Check that the right channel has been found.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'50 Damage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'50 Damage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mJSONStructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'File'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Channel Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'50 Damage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#Add the data sets together into the storage array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'97 Damage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'97 Damage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mJSONStructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'File'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Channel Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'97 Damage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#Add the data sets together into the storage array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Stress Range'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJSONStructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'File'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Channel Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Maximum Stress'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mJSONStructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'File'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Channel Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Minimum Stress'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Calculate stress range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '50 Damage'"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "##########     POST PROCESSING OF DATASET   ###########\n",
    "#######################################################\n",
    "\n",
    "dataset = []\n",
    "channelList = ['Channel 1.1', 'Channel 1.2','Channel 1.3','Channel 1.4','Channel 2.1','Channel 2.2','Channel 2.3','Channel 2.4']\n",
    "for j in range(len(channelList)):\n",
    "    dataset.append({\n",
    "        'name' : channelList[j],\n",
    "        '50 Damage' : 0 ,\n",
    "        '97 Damage':0,\n",
    "        'Stress Range':[],\n",
    "        'Maximum Stress Range':0,\n",
    "    })  \n",
    "for i in range(len(JSONStructure)):#Loop throguh the JSON object , and view each file name.\n",
    "    for j in range(len(JSONStructure[i]['File']['Channel Data'])): #Loop through the channel data to view each channel dataset.      \n",
    "        ChannelName = JSONStructure[i]['File']['Channel Data'][j]['Channel Name'] # define a variable to channelname.\n",
    "        for j in range(len(channelList)):#Loop through the summary data array and find the place to put the data.\n",
    "            if ChannelName == dataset[j]['name']:#Check that the right channel has been found.\n",
    "                dataset[j]['50 Damage'] = dataset[j]['50 Damage'] + JSONStructure[i]['File']['Channel Data'][j]['50 Damage']#Add the data sets together into the storage array.\n",
    "                dataset[j]['97 Damage'] = dataset[j]['97 Damage'] + JSONStructure[i]['File']['Channel Data'][j]['97 Damage']#Add the data sets together into the storage array.\n",
    "                dataset[j]['Stress Range'].append(JSONStructure[i]['File']['Channel Data'][j]['Maximum Stress'] -JSONStructure[i]['File']['Channel Data'][j]['Minimum Stress']) # Calculate stress range \n",
    "for i in range(len(dataset)):\n",
    "    dataset[i]['Maximum Stress Range']  = max(dataset[i]['Stress Range']) \n",
    "    dataset[i].pop('Stress Range')\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo #import the pymongo pip\n",
    "import datetime\n",
    "#mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://heroku_6x00zflw:muikokfevp1h13d5pu0ph74p21@ds161109.mlab.com:61109/heroku_6x00zflw?retryWrites=false')\n",
    "db = client.test_database\n",
    "db = client['heroku_6x00zflw']\n",
    "collection = db['fines']\n",
    " \n",
    "post = {\"author\": \"jon\",\n",
    "        'data':JSONStructure,\n",
    "        'summary':dataset,\n",
    "       }\n",
    "post_id = collection.insert_one(post)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.177529361E-7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
